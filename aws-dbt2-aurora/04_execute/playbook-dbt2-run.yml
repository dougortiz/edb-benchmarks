---
- hosts: dbt2_driver
  name: Run DBT2
  gather_facts: true

  collections:
    - edb_devops.edb_postgres

  tasks:
    - name: Load servers.yml
      ansible.builtin.include_vars:
        file: "{{ terraform_project_path }}/servers.yml"
        name: infra

    # DBT-2 driver bug workaround.
    - name: Ensure required packages are installed
      ansible.builtin.package:
        name:
        - bind-utils
      become: true

    - name: Get IP address of DBaaS system
      ansible.builtin.command:
        cmd: dig {{ infra.servers.aurora.postgres.public_ip }} +short
      register: address

    - name: Make sure DBT2 target data dir and archive do not exist
      ansible.builtin.file:
        path: "{{ item }}"
        state: absent
      become: true
      loop:
        - /tmp/dbt2-data
        - /tmp/dbt2-data.tar.gz

    - name: Display dbt2_connections and ansible_processor_nproc
      ansible.builtin.debug:
        msg:
        - "dbt2_connections: {{ dbt2_connections }}"
        - "ansible_processor_nproc: {{ ansible_processor_nproc }}"

    - name: Calculate drivers per processor
      ansible.builtin.set_fact:
        fpp: "{{ ((dbt2_connections | int) / ansible_processor_nproc) | int  }}"

    - name: Get start time
      include_role:
        name: get-aws-cloudwatch-aurora-postgres-stats
        tasks_from: get-start-time.yml

    # Use dbt2_connections as a limit to the number of connections that may be
    # opened, which in units matching the number of processors on the driver
    # system.  This is a bit of a dirty hack that could be clarified.
    - name: Calculate drivers per processor
      ansible.builtin.set_fact:
        fpp: "{{ ((dbt2_connections | int) / ansible_processor_nproc) | int  }}"

    # Convert the ramp up time minutes to milliseconds and calculate connection
    # delay based on the targeted ramp up time.
    - name: Calculate connection delay
      ansible.builtin.set_fact:
        connection_delay: "{{ ((dbt2_rampup | int) * 60000 / ((fpp | int) * \
                          ansible_processor_nproc)) | int }}"

    - name: Start dbt2-run-workload
      ansible.builtin.command:
        cmd: >-
          dbt2 run
            --comment "Aurora PostgreSQL {{ infra.servers.aurora.postgres.instance_type }} | driver {{ infra.servers.machines["dbt2-driver"].instance_type }}"
              --connection-delay={{ connection_delay }}
              --connections-per-processor={{ fpp }}
              --db-host={{ address.stdout_lines[-1] }}
              --db-port={{ infra.servers.aurora.postgres.port }}
              --dbaas
              --districts 1
              --duration={{ dbt2_duration }}
              --stats
              --warehouses={{ dbt2_warehouse }}
              pgsql
              /tmp/dbt2-data
      environment:
        PGHOST: "{{ address.stdout_lines[-1] }}"
      become: true
      become_user: "{{ pg_owner }}"
      changed_when: false
      register: result

    - name: Workload execution output
      ansible.builtin.debug:
        var: result

    - name: Get end time
      include_role:
        name: get-aws-cloudwatch-aurora-postgres-stats
        tasks_from: get-end-time.yml

    - name: Create logs directory
      local_action: 
        module: ansible.builtin.file
        path: "{{ logs_directory }}"
        state: directory

    - name: Get Postgres error log names
      local_action:
        module: ansible.builtin.shell
        cmd: >-
          aws rds describe-db-log-files
          --db-instance-identifier {{ infra.servers.aurora.postgres.resource_id.0 }}
          | jq -r '.DescribeDBLogFiles[] | .LogFileName'
      register: logfiles

    - name: Get Postgres error logs
      local_action:
        module: ansible.builtin.shell
        cmd: >-
          aws rds download-db-log-file-portion
          --db-instance-identifier {{ infra.servers.aurora.postgres.resource_id.0 }}
          --log-file-name {{ item }}
          --starting-token 0
          --region {{ infra.servers.aurora.postgres.region }}
          > {{ logs_directory }}/{{ item | basename }}.json
      with_items: "{{ logfiles.stdout_lines }}"

    - name: Generate DBT2 report
      ansible.builtin.command:
        cmd: >-
          dbt2 report --html /tmp/dbt2-data
      become: true
      become_user: "{{ pg_owner }}"
      changed_when: false
      register: result

    - name: Report generation output
      ansible.builtin.debug:
        var: result

    - name: Create data archive on remote
      ansible.builtin.command:
        cmd: tar cvzf /tmp/dbt2-data.tar.gz -C /tmp/dbt2-data/ .

    - name: Fetch DBT2 data files to localhost
      ansible.builtin.fetch:
        src: "/tmp/dbt2-data.tar.gz"
        dest: "{{ results_directory }}/"
        flat: true

    - name: Extract data contents to localhost results directory
      ansible.builtin.shell:
        cmd: |
          tar xzf "{{ results_directory }}/dbt2-data.tar.gz" -C "{{ results_directory }}"
      delegate_to: localhost

    - name: Process metrics
      include_role:
        name: get-aws-cloudwatch-aurora-postgres-stats
        tasks_from: process-metrics.yml
